{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer.six in c:\\users\\annisa rizki\\anaconda3\\lib\\site-packages (20221105)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\annisa rizki\\anaconda3\\lib\\site-packages (from pdfminer.six) (38.0.4)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\annisa rizki\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\annisa rizki\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\annisa rizki\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, csv\n",
    "import re\n",
    "from pdfminer.high_level import extract_text_to_fp, extract_pages\n",
    "from pdfminer.layout import LAParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(file_path):\n",
    "    # Create a buffer to store the extracted text\n",
    "    buf = io.StringIO()\n",
    "    \n",
    "    # Extract the text using pdfminer\n",
    "    with open(file_path, 'rb') as fp:\n",
    "        extract_text_to_fp(fp, buf, laparams=LAParams())\n",
    "    \n",
    "    # Preprocess the text to remove unnecessary whitespace and line breaks\n",
    "    text = buf.getvalue().strip()\n",
    "\n",
    "    # Exclude pages that contain \"DAFTAR ISI\" or \"DAFTAR TABEL\"\n",
    "    pages = text.split('\\x0c')\n",
    "    exclude_list = [\"DAFTAR ISI\", \"DAFTAR TABEL\", \"PRAKATA\", \"PENDAHULUAN\", \"LAMPIRAN I\", \n",
    "                    \"Format 1\", \"Format 4\", \"Format 5\", \"Format 6\", \"PROGRAM PEMAGANGAN\", \n",
    "                    \"KURIKULUM PROGRAM PEMAGANGAN\", \"SILABUS PROGRAM PEMAGANGAN\", \"LAMPIRAN II\",\n",
    "                    \"LAMPIRAN III\", \"   1. JADWAL PEMAGANGAN\", \"2. KEGIATAN HARIAN PESERTA YANG DIKETAHUI PEMBIMBING\",\n",
    "                    \"TABEL\", \"LAMPIRAN\"\n",
    "                    ]\n",
    "    pages = [page for page in pages if not any(exclude_str in page for exclude_str in exclude_list)]\n",
    "    text = '\\x0c'.join(pages)\n",
    "    \n",
    "    # Split the text into paragraphs based on subheadings\n",
    "    subheading_pattern = re.compile(r'^[A-Z]\\.\\s|\\bBAB\\s+(?![ivx]+\\b)|\\bBAB\\s+[ivx]+\\s+', re.MULTILINE)\n",
    "    paragraphs = []\n",
    "    \n",
    "    matches = subheading_pattern.finditer(text)\n",
    "    start = 0\n",
    "    \n",
    "    for match in matches:\n",
    "        paragraph = text[start:match.start()].strip()\n",
    "        paragraph = re.sub(r'\\s+', ' ', paragraph)\n",
    "        # Remove numbers between dashes\n",
    "        paragraph = re.sub(r'-\\s*\\d+\\s*-', ' ', paragraph)\n",
    "        # Remove numbers followed by \"http://jdih.pu.go.id\"\n",
    "        paragraph = re.sub(r'\\d+\\s*http://jdih\\.pu\\.go\\.id', '', paragraph)\n",
    "        # Remove Roman numerals\n",
    "        paragraph = re.sub(r'\\b[ivx]+\\b', '', paragraph)\n",
    "        paragraphs.append(paragraph)\n",
    "        start = match.start()\n",
    "\n",
    "    paragraph = text[start:].strip()\n",
    "    paragraph = re.sub(r'\\s+', ' ', paragraph)\n",
    "    # Remove numbers between dashes\n",
    "    paragraph = re.sub(r'-\\s*\\d+\\s*-', ' ', paragraph)\n",
    "    # Remove numbers followed by \"http://jdih.pu.go.id\"\n",
    "    paragraph = re.sub(r'\\d+\\s*http://jdih\\.pu\\.go\\.id', '', paragraph)\n",
    "    # Remove Roman numerals\n",
    "    paragraph = re.sub(r'\\b[ivx]+\\b', '', paragraph)\n",
    "    paragraphs.append(paragraph)\n",
    "\n",
    "    # Remove specific words from each paragraph\n",
    "    remove_words = [\"Dokumen ini tidak dikendalikan jika di unduh/Uncontrolled when downloaded\", \n",
    "                    \"Ditetapkan di Jakarta pada tanggal 6 Desember 2019 MENTERI PEKERJAAN UMUM DAN PERUMAHAN RAKYAT, ttd\",\n",
    "                    \"M. BASUKI HADIMULJONO\",\n",
    "                    \"www.djpp.depkumham.go.id\",\n",
    "                    \"Format 2:\",\n",
    "                    \"2. Tahap Pemagangan dan Evaluasi Pelaksanaan Pemagangan 8 9 10 11 SELESAI Persiapan Pemagangan Pelaksanaan Pemagangan Pengawasan Pelaksanaan Pemagangan Evaluasi Pelaksanaan Pemagangan\",\n",
    "                    \"SALINAN\"]\n",
    "    for i in range(len(paragraphs)):\n",
    "        for word in remove_words:\n",
    "            paragraphs[i] = paragraphs[i].replace(word, \"\")\n",
    "        \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path containing PDF files\n",
    "pdf_dir_path = r\"C:\\Users\\Annisa Rizki\\Desktop\\Annisa Lianda\\Job Freelance\\chatbot_using_openai\\pdf\"\n",
    "\n",
    "# Output CSV file path\n",
    "output_csv = \"output.csv\"\n",
    "\n",
    "# List to store the extracted paragraphs\n",
    "paragraphs_list = []\n",
    "\n",
    "# Loop through all PDF files in the directory\n",
    "for filename in os.listdir(pdf_dir_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        # Extract paragraphs from the PDF file\n",
    "        paragraphs = extract_info(os.path.join(pdf_dir_path, filename))\n",
    "        \n",
    "        # Append the paragraphs to the list with the filename\n",
    "        for paragraph in paragraphs:\n",
    "            paragraphs_list.append([paragraph, filename])\n",
    "        \n",
    "# Write the paragraphs to a CSV file\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Paragraph\", \"Filename\"])\n",
    "    writer.writerows(paragraphs_list)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2ea2127a095dc42a6926c79ee0a030828aff74e0f90a81f566bc982eef7e1b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
